{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "import cufflinks\n",
    "cufflinks.go_offline(connected=True)\n",
    "init_notebook_mode(connected=True)\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_row', 50)\n",
    "pd.set_option('display.max_column', 150)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "Submission = pd.read_csv(\"sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.drop([\"target\",\"id\"],axis=1)\n",
    "train_y = pd.DataFrame(train[\"target\"])\n",
    "test_x = test.drop(\"id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummies(df,column_name):\n",
    "    dummies = pd.get_dummies(df[column_name],prefix=column_name)\n",
    "    df = pd.concat([df,dummies],axis=1)\n",
    "    return df\n",
    "\n",
    "train_y_class = create_dummies(train_y,\"target\").drop(\"target\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features Transformation\n",
    "train_x_log = train_x.apply(lambda x: np.log(x+1))\n",
    "test_x_log = test_x.apply(lambda x: np.log(x+1))\n",
    "train_x_log_sqrt = train_x.apply(lambda x: np.sqrt(np.log(x+1)))\n",
    "test_x_log_sqrt = test_x.apply(lambda x: np.sqrt(np.log(x+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the unique columns value no. between train and test set\n",
    "compare_list = []\n",
    "for columns in train_x.columns:\n",
    "    a = len(train_x[columns].unique())\n",
    "    b = len(test_x[columns].unique())\n",
    "    if a != b:\n",
    "        compare_list.append(columns)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61878, 93)\n",
      "(144368, 93)\n",
      "(61878, 93)\n",
      "(144368, 93)\n",
      "(61878, 93)\n",
      "(144368, 93)\n",
      "(61878, 9)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(test_x.shape)\n",
    "print(train_x_log.shape)\n",
    "print(test_x_log.shape)\n",
    "print(train_x_log_sqrt.shape)\n",
    "print(test_x_log_sqrt.shape)\n",
    "print(train_y_class.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.5\n",
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another method to reset the model weights\n",
    "# model.save_weights('model_reset_weights.h5')\n",
    "# model.load_weights('model_reset_weights.h5')\n",
    "\n",
    "# Regularization layer\n",
    "# model.add(Dense(int(number_of_neurons), activation = 'relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "# model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To have reproducible result with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "from keras import backend\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reset_Model trained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(model):\n",
    "    session = backend.get_session()\n",
    "    for layer in model.layers: \n",
    "        if hasattr(layer, 'kernel_initializer'):\n",
    "            layer.kernel.initializer.run(session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Neural Network, train with Original Dataset (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(units=256,activation = \"relu\",kernel_regularizer=regularizers.l2(0.36), input_dim=93))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=128,activation = \"relu\", kernel_regularizer=regularizers.l2(0.36)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=64,activation = \"relu\", kernel_regularizer=regularizers.l2(0.36)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=32,activation = \"relu\", kernel_regularizer=regularizers.l2(0.36)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=16,activation = \"relu\", kernel_regularizer=regularizers.l2(0.36)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(9, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False, decay = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam, loss='categorical_crossentropy') #loss = loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple early stopping\n",
    "# mode = min or max the monitor loss function\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=30,baseline=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x,train_y_class,validation_split=0.10,\n",
    "          batch_size=(int(train_x.shape[0]*0.2)),\n",
    "          epochs=5000,verbose=1, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(backend.eval(model.optimizer.lr)) # print model learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_per_epoch = pd.DataFrame(model.history.history)\n",
    "loss_per_epoch.iplot(y=[\"loss\",\"val_loss\"], title = \"loss_per_epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = pd.DataFrame(model.predict(train_x),columns = train_y_class.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_pred_class = (pd.DataFrame(model.predict_classes(train_x), columns = [\"predicted_class\"])) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_submission = pd.DataFrame(model.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission[['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6',\n",
    "       'Class_7', 'Class_8', 'Class_9']] = NN_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a Submission File to submit to Kaggle competition ##\n",
    "Submission.to_csv(\"Neural_Network_Ori_X.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Full Training Dataset for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=105,units=12))\n",
    "model.add(Dense(units=8))\n",
    "model.add(Dense(units=4))\n",
    "model.add(Dense(1, activation = \"relu\"))\n",
    "model.compile(optimizer='adam', loss='mse', metrics = [rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x,train_y_class,batch_size=1,epochs=1000,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_submission = pd.DataFrame(model.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission[['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6',\n",
    "       'Class_7', 'Class_8', 'Class_9']] = NN_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a Submission File to submit to Kaggle competition ##\n",
    "Submission.to_csv(\"Neural_Network_Ori_X.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Neural_Network_Ori_X.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "Load_model = load_model('Neural_Network_Ori_X.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Load_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_submission = pd.DataFrame(Load_model.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission[['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6',\n",
    "       'Class_7', 'Class_8', 'Class_9']] = NN_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Neural Network, train with Original Dataset log(X+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(units=93,activation = \"relu\",kernel_regularizer=regularizers.l2(0.0016), input_dim=93))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=46,activation = \"relu\", kernel_regularizer=regularizers.l2(0.0016)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=32,activation = \"relu\", kernel_regularizer=regularizers.l2(0.0016)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=16,activation = \"relu\", kernel_regularizer=regularizers.l2(0.0016)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=8,activation = \"relu\", kernel_regularizer=regularizers.l2(0.0016)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(9, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False, decay = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam, loss='categorical_crossentropy') #loss = loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple early stopping\n",
    "# mode = min or max the monitor loss function\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=10,baseline=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x_log,train_y_class,validation_split=0.10,\n",
    "          batch_size=(int(train_x.shape[0]*0.2)),\n",
    "          epochs=5000,verbose=1, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(backend.eval(model.optimizer.lr)) # print model learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss_per_epoch = pd.DataFrame(model.history.history)\n",
    "loss_per_epoch.iplot(y=[\"loss\",\"val_loss\"], title = \"loss_per_epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = pd.DataFrame(model.predict(train_x),columns = train_y_class.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_pred_class = (pd.DataFrame(model.predict_classes(train_x), columns = [\"predicted_class\"])) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_submission = pd.DataFrame(model.predict(test_x_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission[['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6',\n",
    "       'Class_7', 'Class_8', 'Class_9']] = NN_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a Submission File to submit to Kaggle competition ##\n",
    "Submission.to_csv(\"Neural_Network_log_X.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Full Training Dataset for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=105,units=12))\n",
    "model.add(Dense(units=8))\n",
    "model.add(Dense(units=4))\n",
    "model.add(Dense(1, activation = \"relu\"))\n",
    "model.compile(optimizer='adam', loss='mse', metrics = [rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x,train_y_class,batch_size=1,epochs=1000,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_submission = pd.DataFrame(model.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission[['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6',\n",
    "       'Class_7', 'Class_8', 'Class_9']] = NN_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a Submission File to submit to Kaggle competition ##\n",
    "Submission.to_csv(\"Neural_Network_Ori_X.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Neural_Network_Ori_X.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "Load_model = load_model('Neural_Network_Ori_X.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Load_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_submission = pd.DataFrame(Load_model.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission[['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6',\n",
    "       'Class_7', 'Class_8', 'Class_9']] = NN_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a Submission File to submit to Kaggle competition ##\n",
    "Submission.to_csv(\"Neural_Network_Ori_X.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Neural Network, train with Original Dataset sqrt(log(X+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/cheechingeng/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(units=256,activation = \"relu\",kernel_regularizer=regularizers.l2(0.08), input_dim=93))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=128,activation = \"relu\", kernel_regularizer=regularizers.l2(0.08)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=64,activation = \"relu\", kernel_regularizer=regularizers.l2(0.08)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=32,activation = \"relu\", kernel_regularizer=regularizers.l2(0.08)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=16,activation = \"relu\", kernel_regularizer=regularizers.l2(0.08)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(9, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False, decay = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam, loss='categorical_crossentropy') #loss = loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple early stopping\n",
    "# mode = min or max the monitor loss function\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=50,baseline=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/cheechingeng/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 55690 samples, validate on 6188 samples\n",
      "Epoch 1/5000\n",
      "55690/55690 [==============================] - 3s 60us/step - loss: 38.0087 - val_loss: 36.5303\n",
      "Epoch 2/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 34.5714 - val_loss: 33.3096\n",
      "Epoch 3/5000\n",
      "55690/55690 [==============================] - 2s 33us/step - loss: 31.2941 - val_loss: 30.2556\n",
      "Epoch 4/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 28.2469 - val_loss: 27.4360\n",
      "Epoch 5/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 25.4501 - val_loss: 24.8673\n",
      "Epoch 6/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 22.9060 - val_loss: 22.5423\n",
      "Epoch 7/5000\n",
      "55690/55690 [==============================] - 2s 31us/step - loss: 20.6077 - val_loss: 20.4667\n",
      "Epoch 8/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 18.5379 - val_loss: 18.6233\n",
      "Epoch 9/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 16.6782 - val_loss: 16.9785\n",
      "Epoch 10/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 15.0107 - val_loss: 15.5117\n",
      "Epoch 11/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 13.5179 - val_loss: 14.2047\n",
      "Epoch 12/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 12.1809 - val_loss: 13.0539\n",
      "Epoch 13/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 10.9857 - val_loss: 12.0355\n",
      "Epoch 14/5000\n",
      "55690/55690 [==============================] - 2s 31us/step - loss: 9.9176 - val_loss: 11.1313\n",
      "Epoch 15/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 8.9633 - val_loss: 10.3292\n",
      "Epoch 16/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 8.1103 - val_loss: 9.6171\n",
      "Epoch 17/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 7.3482 - val_loss: 8.9771\n",
      "Epoch 18/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 6.6671 - val_loss: 8.4091\n",
      "Epoch 19/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 6.0585 - val_loss: 7.9055\n",
      "Epoch 20/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 5.5157 - val_loss: 7.4526\n",
      "Epoch 21/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 5.0289 - val_loss: 7.0432\n",
      "Epoch 22/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 4.5941 - val_loss: 6.6991\n",
      "Epoch 23/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 4.2076 - val_loss: 6.3868\n",
      "Epoch 24/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 3.8574 - val_loss: 6.1072\n",
      "Epoch 25/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 3.5466 - val_loss: 5.8480\n",
      "Epoch 26/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 3.2762 - val_loss: 5.6104\n",
      "Epoch 27/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 3.0262 - val_loss: 5.4003\n",
      "Epoch 28/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 2.8025 - val_loss: 5.2145\n",
      "Epoch 29/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 2.6076 - val_loss: 5.0442\n",
      "Epoch 30/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 2.4225 - val_loss: 4.8750\n",
      "Epoch 31/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 2.2624 - val_loss: 4.7486\n",
      "Epoch 32/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 2.1220 - val_loss: 4.6158\n",
      "Epoch 33/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 2.0034 - val_loss: 4.5169\n",
      "Epoch 34/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 1.8817 - val_loss: 4.4011\n",
      "Epoch 35/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 1.7769 - val_loss: 4.3127\n",
      "Epoch 36/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 1.6820 - val_loss: 4.2241\n",
      "Epoch 37/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 1.5928 - val_loss: 4.1506\n",
      "Epoch 38/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 1.5166 - val_loss: 4.0599\n",
      "Epoch 39/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 1.4500 - val_loss: 4.0011\n",
      "Epoch 40/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 1.3820 - val_loss: 3.9547\n",
      "Epoch 41/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 1.3167 - val_loss: 3.8914\n",
      "Epoch 42/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 1.2567 - val_loss: 3.8473\n",
      "Epoch 43/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 1.2089 - val_loss: 3.8161\n",
      "Epoch 44/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 1.1564 - val_loss: 3.7768\n",
      "Epoch 45/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 1.1096 - val_loss: 3.7410\n",
      "Epoch 46/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 1.0686 - val_loss: 3.7159\n",
      "Epoch 47/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 1.0241 - val_loss: 3.6652\n",
      "Epoch 48/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.9787 - val_loss: 3.6376\n",
      "Epoch 49/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.9577 - val_loss: 3.5920\n",
      "Epoch 50/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.9307 - val_loss: 3.5732\n",
      "Epoch 51/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.8926 - val_loss: 3.5621\n",
      "Epoch 52/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.8630 - val_loss: 3.5356\n",
      "Epoch 53/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.8339 - val_loss: 3.4925\n",
      "Epoch 54/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.8035 - val_loss: 3.4625\n",
      "Epoch 55/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.7872 - val_loss: 3.4650\n",
      "Epoch 56/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.7723 - val_loss: 3.4424\n",
      "Epoch 57/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.7507 - val_loss: 3.4236\n",
      "Epoch 58/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.7305 - val_loss: 3.4104\n",
      "Epoch 59/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.7079 - val_loss: 3.3975\n",
      "Epoch 60/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.6847 - val_loss: 3.3920\n",
      "Epoch 61/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.6700 - val_loss: 3.3627\n",
      "Epoch 62/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.6469 - val_loss: 3.3550\n",
      "Epoch 63/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.6360 - val_loss: 3.3528\n",
      "Epoch 64/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.6306 - val_loss: 3.3140\n",
      "Epoch 65/5000\n",
      "55690/55690 [==============================] - 2s 34us/step - loss: 0.6164 - val_loss: 3.2981\n",
      "Epoch 66/5000\n",
      "55690/55690 [==============================] - 2s 36us/step - loss: 0.6020 - val_loss: 3.2846\n",
      "Epoch 67/5000\n",
      "55690/55690 [==============================] - 2s 34us/step - loss: 0.5861 - val_loss: 3.2496\n",
      "Epoch 68/5000\n",
      "55690/55690 [==============================] - 2s 35us/step - loss: 0.5687 - val_loss: 3.2453\n",
      "Epoch 69/5000\n",
      "55690/55690 [==============================] - 2s 31us/step - loss: 0.5587 - val_loss: 3.2277\n",
      "Epoch 70/5000\n",
      "55690/55690 [==============================] - 2s 31us/step - loss: 0.5388 - val_loss: 3.2130\n",
      "Epoch 71/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.5232 - val_loss: 3.1971\n",
      "Epoch 72/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.5193 - val_loss: 3.2021\n",
      "Epoch 73/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.5075 - val_loss: 3.2172\n",
      "Epoch 74/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.5223 - val_loss: 3.2186\n",
      "Epoch 75/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.5372 - val_loss: 3.1833\n",
      "Epoch 76/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.5181 - val_loss: 3.2262\n",
      "Epoch 77/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.4957 - val_loss: 3.2030\n",
      "Epoch 78/5000\n",
      "55690/55690 [==============================] - 2s 31us/step - loss: 0.4824 - val_loss: 3.1959\n",
      "Epoch 79/5000\n",
      "55690/55690 [==============================] - 2s 32us/step - loss: 0.4641 - val_loss: 3.1794\n",
      "Epoch 80/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.4514 - val_loss: 3.1380\n",
      "Epoch 81/5000\n",
      "55690/55690 [==============================] - 2s 32us/step - loss: 0.4435 - val_loss: 3.1660\n",
      "Epoch 82/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.4369 - val_loss: 3.1145\n",
      "Epoch 83/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.4253 - val_loss: 3.0936\n",
      "Epoch 84/5000\n",
      "55690/55690 [==============================] - 2s 33us/step - loss: 0.4466 - val_loss: 3.1039\n",
      "Epoch 85/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.4396 - val_loss: 3.0997\n",
      "Epoch 86/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.4270 - val_loss: 3.1021\n",
      "Epoch 87/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.4056 - val_loss: 3.1217\n",
      "Epoch 88/5000\n",
      "55690/55690 [==============================] - 2s 31us/step - loss: 0.4091 - val_loss: 3.1102\n",
      "Epoch 89/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.4120 - val_loss: 3.0691\n",
      "Epoch 90/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.4060 - val_loss: 3.0704\n",
      "Epoch 91/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.3931 - val_loss: 3.0696\n",
      "Epoch 92/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.3909 - val_loss: 3.1081\n",
      "Epoch 93/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.3857 - val_loss: 3.0834\n",
      "Epoch 94/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.3817 - val_loss: 3.0786\n",
      "Epoch 95/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.3682 - val_loss: 3.0718\n",
      "Epoch 96/5000\n",
      "55690/55690 [==============================] - 2s 31us/step - loss: 0.3715 - val_loss: 3.0607\n",
      "Epoch 97/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.3626 - val_loss: 3.0607\n",
      "Epoch 98/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.3553 - val_loss: 3.0074\n",
      "Epoch 99/5000\n",
      "55690/55690 [==============================] - 2s 32us/step - loss: 0.3436 - val_loss: 3.0253\n",
      "Epoch 100/5000\n",
      "55690/55690 [==============================] - 2s 34us/step - loss: 0.3404 - val_loss: 3.0402\n",
      "Epoch 101/5000\n",
      "55690/55690 [==============================] - 2s 35us/step - loss: 0.3487 - val_loss: 3.0261\n",
      "Epoch 102/5000\n",
      "55690/55690 [==============================] - 2s 34us/step - loss: 0.3394 - val_loss: 3.0197\n",
      "Epoch 103/5000\n",
      "55690/55690 [==============================] - 2s 33us/step - loss: 0.3477 - val_loss: 3.0261\n",
      "Epoch 104/5000\n",
      "55690/55690 [==============================] - 2s 31us/step - loss: 0.3393 - val_loss: 3.0144\n",
      "Epoch 105/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.3344 - val_loss: 3.0374\n",
      "Epoch 106/5000\n",
      "55690/55690 [==============================] - 2s 32us/step - loss: 0.3377 - val_loss: 3.0472\n",
      "Epoch 107/5000\n",
      "55690/55690 [==============================] - 2s 31us/step - loss: 0.3423 - val_loss: 3.0666\n",
      "Epoch 108/5000\n",
      "55690/55690 [==============================] - 2s 32us/step - loss: 0.3317 - val_loss: 3.0447\n",
      "Epoch 109/5000\n",
      "55690/55690 [==============================] - 2s 31us/step - loss: 0.3248 - val_loss: 2.9935\n",
      "Epoch 110/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.3305 - val_loss: 3.0035\n",
      "Epoch 111/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.3431 - val_loss: 3.0526\n",
      "Epoch 112/5000\n",
      "55690/55690 [==============================] - 2s 31us/step - loss: 0.3310 - val_loss: 3.0527\n",
      "Epoch 113/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.3223 - val_loss: 3.0759\n",
      "Epoch 114/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.3171 - val_loss: 3.0689\n",
      "Epoch 115/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.3146 - val_loss: 3.0914\n",
      "Epoch 116/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.3126 - val_loss: 3.0457\n",
      "Epoch 117/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.3083 - val_loss: 3.0080\n",
      "Epoch 118/5000\n",
      "55690/55690 [==============================] - 2s 31us/step - loss: 0.3019 - val_loss: 3.0165\n",
      "Epoch 119/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.3013 - val_loss: 3.0816\n",
      "Epoch 120/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.3020 - val_loss: 3.0407\n",
      "Epoch 121/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.2959 - val_loss: 3.1028\n",
      "Epoch 122/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.3004 - val_loss: 3.1062\n",
      "Epoch 123/5000\n",
      "55690/55690 [==============================] - 2s 29us/step - loss: 0.3022 - val_loss: 3.0984\n",
      "Epoch 124/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.2938 - val_loss: 3.1526\n",
      "Epoch 125/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.2908 - val_loss: 3.2122\n",
      "Epoch 126/5000\n",
      "55690/55690 [==============================] - 2s 32us/step - loss: 0.2844 - val_loss: 3.2278\n",
      "Epoch 127/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.2824 - val_loss: 3.2500\n",
      "Epoch 128/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.2890 - val_loss: 3.2045\n",
      "Epoch 129/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.2929 - val_loss: 3.1892\n",
      "Epoch 130/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.2966 - val_loss: 3.2604\n",
      "Epoch 131/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.2861 - val_loss: 3.1890\n",
      "Epoch 132/5000\n",
      "55690/55690 [==============================] - 2s 31us/step - loss: 0.2788 - val_loss: 3.2557\n",
      "Epoch 133/5000\n",
      "55690/55690 [==============================] - 2s 32us/step - loss: 0.2776 - val_loss: 3.2265\n",
      "Epoch 134/5000\n",
      "55690/55690 [==============================] - 2s 32us/step - loss: 0.2728 - val_loss: 3.3160\n",
      "Epoch 135/5000\n",
      "55690/55690 [==============================] - 2s 35us/step - loss: 0.2668 - val_loss: 3.3160\n",
      "Epoch 136/5000\n",
      "55690/55690 [==============================] - 2s 32us/step - loss: 0.2655 - val_loss: 3.3844\n",
      "Epoch 137/5000\n",
      "55690/55690 [==============================] - 2s 31us/step - loss: 0.2637 - val_loss: 3.3867\n",
      "Epoch 138/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.2618 - val_loss: 3.5663\n",
      "Epoch 139/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.2628 - val_loss: 3.4618\n",
      "Epoch 140/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.2666 - val_loss: 3.4833\n",
      "Epoch 141/5000\n",
      "55690/55690 [==============================] - 2s 31us/step - loss: 0.2721 - val_loss: 3.5029\n",
      "Epoch 142/5000\n",
      "55690/55690 [==============================] - 2s 31us/step - loss: 0.2727 - val_loss: 3.5931\n",
      "Epoch 143/5000\n",
      "55690/55690 [==============================] - 2s 32us/step - loss: 0.2736 - val_loss: 3.6450\n",
      "Epoch 144/5000\n",
      "55690/55690 [==============================] - 2s 32us/step - loss: 0.2737 - val_loss: 3.5669\n",
      "Epoch 145/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.2703 - val_loss: 3.7035\n",
      "Epoch 146/5000\n",
      "55690/55690 [==============================] - 2s 31us/step - loss: 0.2699 - val_loss: 3.7137\n",
      "Epoch 147/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.2640 - val_loss: 3.7740\n",
      "Epoch 148/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.2584 - val_loss: 3.6505\n",
      "Epoch 149/5000\n",
      "55690/55690 [==============================] - 2s 32us/step - loss: 0.2511 - val_loss: 3.6577\n",
      "Epoch 150/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.2507 - val_loss: 3.6926\n",
      "Epoch 151/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.2492 - val_loss: 3.7993\n",
      "Epoch 152/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.2588 - val_loss: 3.7716\n",
      "Epoch 153/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.2563 - val_loss: 3.8131\n",
      "Epoch 154/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.2469 - val_loss: 3.9331\n",
      "Epoch 155/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.2462 - val_loss: 3.9525\n",
      "Epoch 156/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.2464 - val_loss: 3.9786\n",
      "Epoch 157/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.2505 - val_loss: 3.9785\n",
      "Epoch 158/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.2497 - val_loss: 3.9678\n",
      "Epoch 159/5000\n",
      "55690/55690 [==============================] - 2s 30us/step - loss: 0.2490 - val_loss: 4.2351\n",
      "Epoch 00159: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c2a113ef0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x_log_sqrt,train_y_class,validation_split=0.10,\n",
    "          batch_size=(int(train_x.shape[0]*0.2)),\n",
    "          epochs=5000,verbose=1, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(backend.eval(model.optimizer.lr)) # print model learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "line": {
          "color": "rgba(255, 153, 51, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "loss",
         "text": "",
         "type": "scatter",
         "uid": "6965bf61-91ea-4066-8819-5610f1764101",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158
         ],
         "y": [
          38.00868165126971,
          34.571363938177996,
          31.294101504967873,
          28.246866752438194,
          25.45014736968753,
          22.905994912926868,
          20.60769788177293,
          18.53789334460721,
          16.678181454402836,
          15.01071399340062,
          13.517867652148485,
          12.18088595189447,
          10.985743579326787,
          9.917645727203144,
          8.96325311414171,
          8.110338567039188,
          7.348215105718118,
          6.667091362136852,
          6.0585134461787,
          5.515651849725127,
          5.0289166293895144,
          4.594105433724175,
          4.2076200985955605,
          3.857424703271968,
          3.5466148678416043,
          3.27621956071941,
          3.0261854766450806,
          2.802541741650116,
          2.6076067876379114,
          2.422450807540244,
          2.2623786698725135,
          2.122035466569355,
          2.003389686126644,
          1.8816925508797457,
          1.7768957594777164,
          1.6820407802636073,
          1.5928301785959336,
          1.5165891659540214,
          1.449965879816109,
          1.382022517815722,
          1.3167310445285996,
          1.256668037947814,
          1.208896281775291,
          1.156392339798295,
          1.109611802446626,
          1.0686204986033694,
          1.02406871967415,
          0.9787306237325653,
          0.9577267101293064,
          0.9306899615957955,
          0.8926203983500908,
          0.8629612192995866,
          0.8339447985165935,
          0.8035461936814285,
          0.7871719257614089,
          0.7723293889465784,
          0.750707216859185,
          0.7305491082136154,
          0.7078779124179719,
          0.684710709084127,
          0.6700379737223215,
          0.6469192699087567,
          0.6360046044139208,
          0.6305748088545208,
          0.6164161348272256,
          0.6020468572490111,
          0.5861122262587045,
          0.5686988716098517,
          0.5587033285532119,
          0.5388075287219202,
          0.5232071527610199,
          0.5192978167891352,
          0.5074962168439626,
          0.5222535420896164,
          0.5372300702315256,
          0.5180777031657383,
          0.495679406682322,
          0.4824276518395739,
          0.46409778768946913,
          0.45141269300587195,
          0.44353309800304186,
          0.43691584771316083,
          0.4252587546403628,
          0.44662107845668325,
          0.4396400105232909,
          0.427012616897918,
          0.4056068380044037,
          0.40910804993343386,
          0.412031790559008,
          0.4059760283500165,
          0.3931176231304091,
          0.39086624349302396,
          0.38567224895478924,
          0.3816787672440996,
          0.36823512323456237,
          0.3715115445004607,
          0.362645032860621,
          0.35533577321482895,
          0.34356518480428394,
          0.34041170891214473,
          0.3486662736314057,
          0.3394308953214364,
          0.347693747901193,
          0.33934057706357934,
          0.33435454852792085,
          0.3377377977944251,
          0.34229146042317926,
          0.3317019923047117,
          0.3247904457562615,
          0.3305279082799433,
          0.3430805701844717,
          0.3310393795282756,
          0.3222854858932257,
          0.31708107709959565,
          0.3145870864043481,
          0.31255249442821303,
          0.30827959610189737,
          0.30191594399184035,
          0.3012630168417451,
          0.30203485258510926,
          0.2959270942444475,
          0.30036460877824117,
          0.3022424985110642,
          0.29379398539103135,
          0.29084807206503815,
          0.28440871406102397,
          0.2823816933169958,
          0.2890298241750409,
          0.2928956115902979,
          0.29655744135112216,
          0.28606458154116826,
          0.2788046372227918,
          0.27756275991966234,
          0.27276921908567314,
          0.26680566093816344,
          0.2655275085682414,
          0.2637025906279092,
          0.26175473933588944,
          0.2628357348969304,
          0.2665995013314617,
          0.27207465891265253,
          0.2726823399858514,
          0.2736083239552405,
          0.27369017843381144,
          0.27033648960871637,
          0.26993485089424246,
          0.26399409777119764,
          0.258414799963942,
          0.25109164031618136,
          0.25067937826581566,
          0.24915666909395717,
          0.25881836901561517,
          0.25630303265580073,
          0.2469259891281074,
          0.2462313249988174,
          0.24640165143882936,
          0.2505459828915342,
          0.2496611545687519,
          0.24897593558557074
         ]
        },
        {
         "line": {
          "color": "rgba(55, 128, 191, 1.0)",
          "dash": "solid",
          "shape": "linear",
          "width": 1.3
         },
         "mode": "lines",
         "name": "val_loss",
         "text": "",
         "type": "scatter",
         "uid": "0bb033c0-5615-4aad-a878-9ba9683f5599",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158
         ],
         "y": [
          36.53025436401367,
          33.309608459472656,
          30.25560188293457,
          27.43600082397461,
          24.86726188659668,
          22.542301177978516,
          20.466650009155273,
          18.623292922973633,
          16.97849464416504,
          15.511666297912598,
          14.204669952392578,
          13.053877830505371,
          12.035503387451172,
          11.131311416625977,
          10.32921314239502,
          9.617069244384766,
          8.977083206176758,
          8.409065246582031,
          7.905542850494385,
          7.452630519866943,
          7.04315710067749,
          6.6991286277771,
          6.386837005615234,
          6.107175827026367,
          5.8479533195495605,
          5.610408782958984,
          5.400269985198975,
          5.21451997756958,
          5.04417610168457,
          4.874969005584717,
          4.74856424331665,
          4.615835189819336,
          4.51685905456543,
          4.401070594787598,
          4.312671184539795,
          4.224118709564209,
          4.150598049163818,
          4.059926509857178,
          4.0010833740234375,
          3.954667568206787,
          3.891350746154785,
          3.8473236560821533,
          3.8160974979400635,
          3.776775360107422,
          3.741028308868408,
          3.71586537361145,
          3.6651690006256104,
          3.6376395225524902,
          3.5919957160949707,
          3.5731825828552246,
          3.562091112136841,
          3.5355684757232666,
          3.4924728870391846,
          3.4624969959259033,
          3.4649710655212402,
          3.4424030780792236,
          3.423552989959717,
          3.4103760719299316,
          3.3975470066070557,
          3.391982078552246,
          3.3626606464385986,
          3.3550033569335938,
          3.3527510166168213,
          3.3140158653259277,
          3.298126220703125,
          3.28460431098938,
          3.249579429626465,
          3.245326519012451,
          3.2276611328125,
          3.2129595279693604,
          3.197082996368408,
          3.2021162509918213,
          3.2172458171844482,
          3.218571662902832,
          3.183347225189209,
          3.226199150085449,
          3.202955961227417,
          3.195875406265259,
          3.179387331008911,
          3.137953519821167,
          3.1660003662109375,
          3.114488363265991,
          3.0935657024383545,
          3.1038568019866943,
          3.099724292755127,
          3.102125883102417,
          3.121678352355957,
          3.1101975440979004,
          3.0690934658050537,
          3.0704104900360107,
          3.0696258544921875,
          3.1081314086914062,
          3.0834052562713623,
          3.0786471366882324,
          3.071847677230835,
          3.060667037963867,
          3.0607357025146484,
          3.0074353218078613,
          3.0252773761749268,
          3.040179491043091,
          3.0260815620422363,
          3.0197198390960693,
          3.0260796546936035,
          3.0144286155700684,
          3.0374460220336914,
          3.0471854209899902,
          3.0665643215179443,
          3.044672727584839,
          2.9934580326080322,
          3.003523111343384,
          3.0526208877563477,
          3.0527265071868896,
          3.0758602619171143,
          3.0688979625701904,
          3.0914337635040283,
          3.0457465648651123,
          3.0079689025878906,
          3.0165491104125977,
          3.0816001892089844,
          3.0406506061553955,
          3.102762222290039,
          3.1062371730804443,
          3.0983569622039795,
          3.1525962352752686,
          3.212200880050659,
          3.227771520614624,
          3.249981641769409,
          3.204484462738037,
          3.1892075538635254,
          3.2604095935821533,
          3.188995838165283,
          3.2556841373443604,
          3.2264606952667236,
          3.315976142883301,
          3.315999746322632,
          3.3843889236450195,
          3.38672137260437,
          3.5663042068481445,
          3.4618468284606934,
          3.4832687377929688,
          3.502920150756836,
          3.593130588531494,
          3.6449503898620605,
          3.56691575050354,
          3.70346999168396,
          3.7136569023132324,
          3.774000883102417,
          3.650529146194458,
          3.6576895713806152,
          3.692554235458374,
          3.7993080615997314,
          3.7716448307037354,
          3.8131086826324463,
          3.9331271648406982,
          3.9525272846221924,
          3.978576183319092,
          3.978543996810913,
          3.967801570892334,
          4.235116958618164
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "title": {
         "font": {
          "color": "#4D5663"
         },
         "text": "loss_per_epoch"
        },
        "xaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        },
        "yaxis": {
         "gridcolor": "#E1E5ED",
         "showgrid": true,
         "tickfont": {
          "color": "#4D5663"
         },
         "title": {
          "font": {
           "color": "#4D5663"
          },
          "text": ""
         },
         "zerolinecolor": "#E1E5ED"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"fcc67c4a-c2bb-409d-8f0d-202664a3c2fa\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"fcc67c4a-c2bb-409d-8f0d-202664a3c2fa\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'fcc67c4a-c2bb-409d-8f0d-202664a3c2fa',\n",
       "                        [{\"line\": {\"color\": \"rgba(255, 153, 51, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"loss\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"6965bf61-91ea-4066-8819-5610f1764101\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158], \"y\": [38.00868165126971, 34.571363938177996, 31.294101504967873, 28.246866752438194, 25.45014736968753, 22.905994912926868, 20.60769788177293, 18.53789334460721, 16.678181454402836, 15.01071399340062, 13.517867652148485, 12.18088595189447, 10.985743579326787, 9.917645727203144, 8.96325311414171, 8.110338567039188, 7.348215105718118, 6.667091362136852, 6.0585134461787, 5.515651849725127, 5.0289166293895144, 4.594105433724175, 4.2076200985955605, 3.857424703271968, 3.5466148678416043, 3.27621956071941, 3.0261854766450806, 2.802541741650116, 2.6076067876379114, 2.422450807540244, 2.2623786698725135, 2.122035466569355, 2.003389686126644, 1.8816925508797457, 1.7768957594777164, 1.6820407802636073, 1.5928301785959336, 1.5165891659540214, 1.449965879816109, 1.382022517815722, 1.3167310445285996, 1.256668037947814, 1.208896281775291, 1.156392339798295, 1.109611802446626, 1.0686204986033694, 1.02406871967415, 0.9787306237325653, 0.9577267101293064, 0.9306899615957955, 0.8926203983500908, 0.8629612192995866, 0.8339447985165935, 0.8035461936814285, 0.7871719257614089, 0.7723293889465784, 0.750707216859185, 0.7305491082136154, 0.7078779124179719, 0.684710709084127, 0.6700379737223215, 0.6469192699087567, 0.6360046044139208, 0.6305748088545208, 0.6164161348272256, 0.6020468572490111, 0.5861122262587045, 0.5686988716098517, 0.5587033285532119, 0.5388075287219202, 0.5232071527610199, 0.5192978167891352, 0.5074962168439626, 0.5222535420896164, 0.5372300702315256, 0.5180777031657383, 0.495679406682322, 0.4824276518395739, 0.46409778768946913, 0.45141269300587195, 0.44353309800304186, 0.43691584771316083, 0.4252587546403628, 0.44662107845668325, 0.4396400105232909, 0.427012616897918, 0.4056068380044037, 0.40910804993343386, 0.412031790559008, 0.4059760283500165, 0.3931176231304091, 0.39086624349302396, 0.38567224895478924, 0.3816787672440996, 0.36823512323456237, 0.3715115445004607, 0.362645032860621, 0.35533577321482895, 0.34356518480428394, 0.34041170891214473, 0.3486662736314057, 0.3394308953214364, 0.347693747901193, 0.33934057706357934, 0.33435454852792085, 0.3377377977944251, 0.34229146042317926, 0.3317019923047117, 0.3247904457562615, 0.3305279082799433, 0.3430805701844717, 0.3310393795282756, 0.3222854858932257, 0.31708107709959565, 0.3145870864043481, 0.31255249442821303, 0.30827959610189737, 0.30191594399184035, 0.3012630168417451, 0.30203485258510926, 0.2959270942444475, 0.30036460877824117, 0.3022424985110642, 0.29379398539103135, 0.29084807206503815, 0.28440871406102397, 0.2823816933169958, 0.2890298241750409, 0.2928956115902979, 0.29655744135112216, 0.28606458154116826, 0.2788046372227918, 0.27756275991966234, 0.27276921908567314, 0.26680566093816344, 0.2655275085682414, 0.2637025906279092, 0.26175473933588944, 0.2628357348969304, 0.2665995013314617, 0.27207465891265253, 0.2726823399858514, 0.2736083239552405, 0.27369017843381144, 0.27033648960871637, 0.26993485089424246, 0.26399409777119764, 0.258414799963942, 0.25109164031618136, 0.25067937826581566, 0.24915666909395717, 0.25881836901561517, 0.25630303265580073, 0.2469259891281074, 0.2462313249988174, 0.24640165143882936, 0.2505459828915342, 0.2496611545687519, 0.24897593558557074]}, {\"line\": {\"color\": \"rgba(55, 128, 191, 1.0)\", \"dash\": \"solid\", \"shape\": \"linear\", \"width\": 1.3}, \"mode\": \"lines\", \"name\": \"val_loss\", \"text\": \"\", \"type\": \"scatter\", \"uid\": \"0bb033c0-5615-4aad-a878-9ba9683f5599\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158], \"y\": [36.53025436401367, 33.309608459472656, 30.25560188293457, 27.43600082397461, 24.86726188659668, 22.542301177978516, 20.466650009155273, 18.623292922973633, 16.97849464416504, 15.511666297912598, 14.204669952392578, 13.053877830505371, 12.035503387451172, 11.131311416625977, 10.32921314239502, 9.617069244384766, 8.977083206176758, 8.409065246582031, 7.905542850494385, 7.452630519866943, 7.04315710067749, 6.6991286277771, 6.386837005615234, 6.107175827026367, 5.8479533195495605, 5.610408782958984, 5.400269985198975, 5.21451997756958, 5.04417610168457, 4.874969005584717, 4.74856424331665, 4.615835189819336, 4.51685905456543, 4.401070594787598, 4.312671184539795, 4.224118709564209, 4.150598049163818, 4.059926509857178, 4.0010833740234375, 3.954667568206787, 3.891350746154785, 3.8473236560821533, 3.8160974979400635, 3.776775360107422, 3.741028308868408, 3.71586537361145, 3.6651690006256104, 3.6376395225524902, 3.5919957160949707, 3.5731825828552246, 3.562091112136841, 3.5355684757232666, 3.4924728870391846, 3.4624969959259033, 3.4649710655212402, 3.4424030780792236, 3.423552989959717, 3.4103760719299316, 3.3975470066070557, 3.391982078552246, 3.3626606464385986, 3.3550033569335938, 3.3527510166168213, 3.3140158653259277, 3.298126220703125, 3.28460431098938, 3.249579429626465, 3.245326519012451, 3.2276611328125, 3.2129595279693604, 3.197082996368408, 3.2021162509918213, 3.2172458171844482, 3.218571662902832, 3.183347225189209, 3.226199150085449, 3.202955961227417, 3.195875406265259, 3.179387331008911, 3.137953519821167, 3.1660003662109375, 3.114488363265991, 3.0935657024383545, 3.1038568019866943, 3.099724292755127, 3.102125883102417, 3.121678352355957, 3.1101975440979004, 3.0690934658050537, 3.0704104900360107, 3.0696258544921875, 3.1081314086914062, 3.0834052562713623, 3.0786471366882324, 3.071847677230835, 3.060667037963867, 3.0607357025146484, 3.0074353218078613, 3.0252773761749268, 3.040179491043091, 3.0260815620422363, 3.0197198390960693, 3.0260796546936035, 3.0144286155700684, 3.0374460220336914, 3.0471854209899902, 3.0665643215179443, 3.044672727584839, 2.9934580326080322, 3.003523111343384, 3.0526208877563477, 3.0527265071868896, 3.0758602619171143, 3.0688979625701904, 3.0914337635040283, 3.0457465648651123, 3.0079689025878906, 3.0165491104125977, 3.0816001892089844, 3.0406506061553955, 3.102762222290039, 3.1062371730804443, 3.0983569622039795, 3.1525962352752686, 3.212200880050659, 3.227771520614624, 3.249981641769409, 3.204484462738037, 3.1892075538635254, 3.2604095935821533, 3.188995838165283, 3.2556841373443604, 3.2264606952667236, 3.315976142883301, 3.315999746322632, 3.3843889236450195, 3.38672137260437, 3.5663042068481445, 3.4618468284606934, 3.4832687377929688, 3.502920150756836, 3.593130588531494, 3.6449503898620605, 3.56691575050354, 3.70346999168396, 3.7136569023132324, 3.774000883102417, 3.650529146194458, 3.6576895713806152, 3.692554235458374, 3.7993080615997314, 3.7716448307037354, 3.8131086826324463, 3.9331271648406982, 3.9525272846221924, 3.978576183319092, 3.978543996810913, 3.967801570892334, 4.235116958618164]}],\n",
       "                        {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"loss_per_epoch\"}, \"xaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}, \"yaxis\": {\"gridcolor\": \"#E1E5ED\", \"showgrid\": true, \"tickfont\": {\"color\": \"#4D5663\"}, \"title\": {\"font\": {\"color\": \"#4D5663\"}, \"text\": \"\"}, \"zerolinecolor\": \"#E1E5ED\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('fcc67c4a-c2bb-409d-8f0d-202664a3c2fa');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_per_epoch = pd.DataFrame(model.history.history)\n",
    "loss_per_epoch.iplot(y=[\"loss\",\"val_loss\"], title = \"loss_per_epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = pd.DataFrame(model.predict(train_x),columns = train_y_class.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_pred_class = (pd.DataFrame(model.predict_classes(train_x), columns = [\"predicted_class\"])) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_submission = pd.DataFrame(model.predict(test_x_log_sqrt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission[['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6',\n",
    "       'Class_7', 'Class_8', 'Class_9']] = NN_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a Submission File to submit to Kaggle competition ##\n",
    "Submission.to_csv(\"Neural_Network_sqrt_log_X.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Full Training Dataset for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim=105,units=12))\n",
    "model.add(Dense(units=8))\n",
    "model.add(Dense(units=4))\n",
    "model.add(Dense(1, activation = \"relu\"))\n",
    "model.compile(optimizer='adam', loss='mse', metrics = [rmse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x,train_y_class,batch_size=1,epochs=1000,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_submission = pd.DataFrame(model.predict(test_x_log_sqrt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission[['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6',\n",
    "       'Class_7', 'Class_8', 'Class_9']] = NN_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a Submission File to submit to Kaggle competition ##\n",
    "Submission.to_csv(\"Neural_Network_Ori_X.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Neural_Network_Ori_X.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "Load_model = load_model('Neural_Network_Ori_X.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Load_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_submission = pd.DataFrame(Load_model.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission[['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6',\n",
    "       'Class_7', 'Class_8', 'Class_9']] = NN_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a Submission File to submit to Kaggle competition ##\n",
    "Submission.to_csv(\"Neural_Network_Ori_X.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a Submission File to submit to Kaggle competition ##\n",
    "Submission.to_csv(\"Neural_Network_Ori_X.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a Submission File to submit to Kaggle competition ##\n",
    "Submission.to_csv(\"Neural_Network_Ori_X.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
