{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cufflinks\n",
    "cufflinks.go_offline(connected=True)\n",
    "init_notebook_mode(connected=True)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "pd.set_option('display.max_row', 100)\n",
    "pd.set_option('display.max_column', 310)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_eng_with_KNN_TSNE_KMean = pd.read_csv(\"train_x_eng_with_KNN_TSNE_KMean.csv\")\n",
    "test_x_eng_with_KNN_TSNE_Kmean = pd.read_csv(\"test_x_eng_with_KNN_TSNE_Kmean.csv\")\n",
    "\n",
    "train_y_class = pd.read_csv(\"train_y_class.csv\")\n",
    "train_y_label = pd.read_csv(\"train_y_label.csv\")\n",
    "\n",
    "Submission = pd.read_csv(\"sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read column names from file\n",
    "cols = list(pd.read_csv(\"XGBoost_test_x_pred.csv\", nrows =1))\n",
    "\n",
    "XGBoost_train_x_pred = pd.read_csv(\"XGBoost_train_x_pred.csv\", names=[\"XGBoost_train_x_pred\" + str(i) for i in range(1,10,1)])[1:].reset_index(drop=True)\n",
    "XGBoost_train_x_log_pred = pd.read_csv(\"XGBoost_train_x_log_pred.csv\", names=[\"XGBoost_train_x_log_pred\" + str(i) for i in range(1,10,1)])[1:].reset_index(drop=True)\n",
    "XGBoost_train_x_eng_pred = pd.read_csv(\"XGBoost_train_x_eng_pred.csv\", names=[\"XGBoost_train_x_eng_pred\" + str(i) for i in range(1,10,1)])[1:].reset_index(drop=True)\n",
    "XGBoost_train_x_log_eng_pred = pd.read_csv(\"XGBoost_train_x_log_eng_pred.csv\", names=[\"XGBoost_train_x_log_eng_pred\" + str(i) for i in range(1,10,1)])[1:].reset_index(drop=True)\n",
    "Neural_Network_train_x_pred = pd.read_csv(\"Neural_Network_train_x_pred.csv\", names=[\"Neural_Network_train_x_pred\" + str(i) for i in range(1,10,1)])[1:].reset_index(drop=True)\n",
    "Neural_Network_train_x_log_pred = pd.read_csv(\"Neural_Network_train_x_log_pred.csv\", names=[\"Neural_Network_train_x_log_pred\" + str(i) for i in range(1,10,1)])[1:].reset_index(drop=True)\n",
    "Neural_Network_train_x_eng_pred = pd.read_csv(\"Neural_Network_train_x_eng_pred.csv\", names=[\"Neural_Network_train_x_eng_pred\" + str(i) for i in range(1,10,1)])[1:].reset_index(drop=True)\n",
    "Neural_Network_train_x_log_eng_pred = pd.read_csv(\"Neural_Network_train_x_log_eng_pred.csv\", names=[\"Neural_Network_train_x_log_eng_pred\" + str(i) for i in range(1,10,1)])[1:].reset_index(drop=True)\n",
    "XGBoost_train_x_eng_pred_drop_KNN = pd.read_csv(\"XGBoost_train_x_eng_pred_drop_KNN.csv\", names=[\"XGBoost_train_x_eng_pred_drop_KNN\" + str(i) for i in range(1,10,1)])[1:].reset_index(drop=True)\n",
    "\n",
    "XGBoost_test_x_pred = pd.read_csv(\"XGBoost_test_x_pred.csv\",usecols =[i for i in cols if i != 'id'])\n",
    "XGBoost_test_x_log_pred = pd.read_csv(\"XGBoost_test_x_log_pred.csv\", usecols =[i for i in cols if i != 'id'])\n",
    "XGBoost_test_x_eng_pred = pd.read_csv(\"XGBoost_test_x_eng_pred.csv\", usecols =[i for i in cols if i != 'id'])\n",
    "XGBoost_test_x_log_eng_pred = pd.read_csv(\"XGBoost_test_x_log_eng_pred.csv\", usecols =[i for i in cols if i != 'id'])\n",
    "Neural_Network_test_x_pred = pd.read_csv(\"Neural_Network_test_x_pred.csv\", usecols =[i for i in cols if i != 'id'])\n",
    "Neural_Network_test_x_log_pred = pd.read_csv(\"Neural_Network_test_x_log_pred.csv\", usecols =[i for i in cols if i != 'id'])\n",
    "Neural_Network_test_x_eng_pred = pd.read_csv(\"Neural_Network_test_x_eng_pred.csv\", usecols =[i for i in cols if i != 'id'])\n",
    "Neural_Network_test_x_log_eng_pred = pd.read_csv(\"Neural_Network_test_x_log_eng_pred.csv\", usecols =[i for i in cols if i != 'id'])\n",
    "XGBoost_test_x_eng_pred_drop_KNN = pd.read_csv(\"XGBoost_test_x_eng_pred_drop_KNN.csv\", usecols =[i for i in cols if i != 'id'])\n",
    "\n",
    "XGBoost_test_x_pred.columns = [\"XGBoost_train_x_pred\" + str(i) for i in range(1,10,1)]\n",
    "XGBoost_test_x_log_pred.columns = [\"XGBoost_train_x_log_pred\" + str(i) for i in range(1,10,1)]\n",
    "XGBoost_test_x_eng_pred.columns = [\"XGBoost_train_x_eng_pred\" + str(i) for i in range(1,10,1)]\n",
    "XGBoost_test_x_log_eng_pred.columns = [\"XGBoost_train_x_log_eng_pred\" + str(i) for i in range(1,10,1)]\n",
    "Neural_Network_test_x_pred.columns = [\"Neural_Network_train_x_pred\" + str(i) for i in range(1,10,1)]\n",
    "Neural_Network_test_x_log_pred.columns = [\"Neural_Network_train_x_log_pred\" + str(i) for i in range(1,10,1)]\n",
    "Neural_Network_test_x_eng_pred.columns = [\"Neural_Network_train_x_eng_pred\" + str(i) for i in range(1,10,1)]\n",
    "Neural_Network_test_x_log_eng_pred.columns = [\"Neural_Network_train_x_log_eng_pred\" + str(i) for i in range(1,10,1)]\n",
    "XGBoost_test_x_eng_pred_drop_KNN.columns = [\"XGBoost_train_x_eng_pred_drop_KNN\" + str(i) for i in range(1,10,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_all_included = pd.concat([train_x_eng_with_KNN_TSNE_KMean,XGBoost_train_x_log_pred,\n",
    "                                  XGBoost_train_x_eng_pred,XGBoost_train_x_log_eng_pred,\n",
    "                                 Neural_Network_train_x_pred,Neural_Network_train_x_log_pred,XGBoost_train_x_eng_pred_drop_KNN,\n",
    "                                 Neural_Network_train_x_eng_pred,Neural_Network_train_x_log_eng_pred],axis=1)\n",
    "\n",
    "test_x_all_included = pd.concat([test_x_eng_with_KNN_TSNE_Kmean,XGBoost_test_x_log_pred,\n",
    "                                  XGBoost_test_x_eng_pred,XGBoost_test_x_log_eng_pred,\n",
    "                                 Neural_Network_test_x_pred,Neural_Network_test_x_log_pred,XGBoost_test_x_eng_pred_drop_KNN,\n",
    "                                 Neural_Network_test_x_eng_pred,Neural_Network_test_x_log_eng_pred],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns_KNN = train_x_eng_with_KNN_TSNE_KMean.loc[:,\"KNN_Feature_1\":\"KNN_Feature_36\"].columns\n",
    "drop_columns_K_Class = train_x_eng_with_KNN_TSNE_KMean.loc[:,\"Class_0\":\"Class_8\"].columns\n",
    "train_x_selected = train_x_eng_with_KNN_TSNE_KMean.drop(drop_columns_KNN,axis=1)\n",
    "train_x_selected = train_x_selected.drop(drop_columns_K_Class,axis=1)\n",
    "test_x_selected = test_x_eng_with_KNN_TSNE_Kmean.drop(drop_columns_KNN,axis=1)\n",
    "test_x_selected = test_x_selected.drop(drop_columns_K_Class,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop KNN & K_Class variable & only included prediction that score well\n",
    "train_x_selected = pd.concat([train_x_selected,XGBoost_train_x_pred,XGBoost_train_x_log_pred,\n",
    "                              XGBoost_train_x_eng_pred_drop_KNN,Neural_Network_train_x_pred,Neural_Network_train_x_log_pred],axis=1)\n",
    "test_x_selected = pd.concat([test_x_selected,XGBoost_test_x_pred,XGBoost_test_x_log_pred,\n",
    "                              XGBoost_test_x_eng_pred_drop_KNN,Neural_Network_test_x_pred,Neural_Network_test_x_log_pred],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "train_score_scaler = StandardScaler()\n",
    "test_score_scaler = StandardScaler()\n",
    "train_x_all_included = pd.DataFrame(train_score_scaler.fit_transform(train_x_all_included),columns = train_x_all_included.columns)\n",
    "test_x_all_included = pd.DataFrame(test_score_scaler.fit_transform(test_x_all_included),columns = test_x_all_included.columns)\n",
    "train_x_selected = pd.DataFrame(train_score_scaler.fit_transform(train_x_selected),columns = train_x_selected.columns)\n",
    "test_x_selected = pd.DataFrame(test_score_scaler.fit_transform(test_x_selected),columns = test_x_selected.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle training data for neural network\n",
    "train_y_class_columns = train_y_class.columns\n",
    "train_x_all_included_s = pd.concat([train_x_all_included,train_y_class],axis=1)\n",
    "train_x_all_included_s = train_x_all_included_s.sample(frac=1)\n",
    "train_x_selected_s = pd.concat([train_x_selected,train_y_class],axis=1)\n",
    "train_x_selected_s = train_x_selected_s.sample(frac=1)\n",
    "\n",
    "# For Xgboost\n",
    "train_y_label_columns = train_y_label.columns\n",
    "train_x_all_included_s_xbg = pd.concat([train_x_all_included,train_y_label],axis=1)\n",
    "train_x_all_included_s_xbg = train_x_all_included_s_xbg.sample(frac=1)\n",
    "train_x_selected_s_xbg = pd.concat([train_x_selected,train_y_label],axis=1)\n",
    "train_x_selected_s_xbg = train_x_selected_s_xbg.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_all_included = train_x_all_included_s.drop(train_y_class_columns,axis=1)\n",
    "train_x_all_included_class = train_x_all_included_s[train_y_class_columns]\n",
    "train_x_selected = train_x_selected_s.drop(train_y_class_columns,axis=1)\n",
    "train_x_selected_class = train_x_selected_s[train_y_class_columns]\n",
    "\n",
    "train_x_all_included_xgb = train_x_all_included_s_xbg.drop(train_y_label_columns,axis=1)\n",
    "train_x_all_included_label = train_x_all_included_s_xbg[train_y_label_columns]\n",
    "train_x_selected_xgb = train_x_selected_s_xbg.drop(train_y_label_columns,axis=1)\n",
    "train_x_selected_label = train_x_selected_s_xbg[train_y_label_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total dataset features to consider\n",
    "print(train_x_all_included.shape)\n",
    "print(test_x_all_included.shape)\n",
    "print(train_x_selected.shape)\n",
    "print(test_x_selected.shape)\n",
    "print(train_x_all_included_xgb.shape)\n",
    "print(train_x_selected_xgb.shape)\n",
    "\n",
    "# Label dataset\n",
    "print(train_x_all_included_class.shape)\n",
    "print(train_x_selected_class.shape)\n",
    "print(train_x_all_included_label.shape)\n",
    "print(train_x_selected_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. XGBoost Model, train_x_all_included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To track the iteration records for parameters tuning\n",
    "best_score_list = []\n",
    "best_params_list = []\n",
    "best_R2_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_tuning = {'learning_rate': [0.1],               # 6th when boosting\n",
    "                          'gamma': [0],                       # 3rd\n",
    "                          'max_depth': [6,7],                     # 1st to tune\n",
    "                          'min_child_weight': [0],              # 2nd\n",
    "                          'max_delta_step': [0],\n",
    "                          'subsample': [0.22,0.5,0.78],                   # 4th\n",
    "                          'colsample_bytree': [0.22,0.5,0.78],            # 4th \n",
    "                          'colsample_bylevel': [1],\n",
    "                          'colsample_bynode': [1],\n",
    "                          'reg_lambda': [0],                    # 5th\n",
    "                          'reg_alpha': [0],                     # 5th\n",
    "                          'scale_pos_weight': [1.0],            # only when dealing with imbalance classes\n",
    "                          'n_estimators': [256],                # 1st\n",
    "                          \"booster\": [\"gbtree\"],\n",
    "                          \"verbosity\": [1],\n",
    "                          \"objective\": [\"multi:softprob\"],\n",
    "                          \"eval_metric\": [\"mlogloss\"],\n",
    "                          \"num_class\": [9],\n",
    "                          \"seed\": [0]\n",
    "                         }                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Parameters setting inside Regressor\n",
    "xgboost = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_grid = GridSearchCV(estimator = xgboost, param_grid = hyperparameters_tuning, cv = 4, iid = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_grid.fit(train_x_all_included_xgb,train_x_all_included_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cv_score = xgboost_grid.cv_results_ #thus no need train-test split, as cv will automatic run for us \n",
    "best_params = xgboost_grid.best_params_\n",
    "best_score = xgboost_grid.best_score_\n",
    "best_rf = xgboost_grid.best_estimator_\n",
    "best_accuracy_score = best_rf.score(train_x_all_included_xgb,train_x_all_included_label)\n",
    "best_score_list.append(best_score)\n",
    "best_params_list.append(best_rf)\n",
    "best_R2_list.append(best_accuracy_score)\n",
    "print(best_score)\n",
    "print(best_accuracy_score)\n",
    "print(best_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_score_list)\n",
    "print(best_R2_list)\n",
    "print(best_params_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create XGBoost's DMatrix, to boosting up the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDMat = xgb.DMatrix(data = train_x_all_included_xgb, label = train_x_all_included_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower the learning_rate and set a large num_boost_round hyperparameter to ensure convergence. \n",
    "# If convergence is slow, retry with a slightly higher learning rate (e.g. 0.075 instead of 0.05)\n",
    "num_boost_round = 15000\n",
    "early_stopping_rounds = 50\n",
    "# Activates early stopping. CV error needs to decrease at least every <early_stopping_rounds> round(s) to continue.\n",
    "# Last entry in evaluation history is the one from best iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_boosting = {'learning_rate': 0.1,               # 6th when boosting\n",
    "                          'gamma': 0,                       # 3rd\n",
    "                          'max_depth': 6,                     # 1st to tune\n",
    "                          'min_child_weight': 0,              # 2nd\n",
    "                          'max_delta_step': 0,\n",
    "                          'subsample': 0.78,                   # 4th\n",
    "                          'colsample_bytree': 0.78,            # 4th \n",
    "                          'colsample_bylevel': 1,\n",
    "                          'colsample_bynode': 1,\n",
    "                          'reg_lambda': 0,                    # 5th\n",
    "                          'reg_alpha': 0,                     # 5th\n",
    "                          'scale_pos_weight': 1.0,            # only when dealing with imbalance classes\n",
    "                          'n_estimators': 1,                # 1st\n",
    "                          \"booster\": \"gbtree\",\n",
    "                          \"verbosity\": 1,\n",
    "                          \"objective\": \"multi:softprob\",\n",
    "                          \"eval_metric\": \"mlogloss\",\n",
    "                          \"num_class\": 9,\n",
    "                          \"seed\": 0\n",
    "                         }                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbCV = xgb.cv(\n",
    "    params = hyperparameters_boosting, \n",
    "    dtrain = trainDMat, \n",
    "    num_boost_round = num_boost_round,\n",
    "    nfold = 4, #same as CV\n",
    "    metrics = {'merror'},\n",
    "    early_stopping_rounds = early_stopping_rounds,\n",
    "    verbose_eval = True,     \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finalise XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round = len(xgbCV)\n",
    "\n",
    "xgbFinal = xgb.train(\n",
    "    params = hyperparameters_boosting, \n",
    "    dtrain = trainDMat, \n",
    "    num_boost_round = num_boost_round,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 40))\n",
    "xgb.plot_importance(xgbFinal, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost_test_x_all_included_pred_after boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBoost_test_x_all_included_pred = xgbFinal.predict(xgb.DMatrix(test_x_all_included))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission = pd.read_csv(\"sampleSubmission.csv\")\n",
    "Submission[['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6',\n",
    "       'Class_7', 'Class_8', 'Class_9']] = XGBoost_test_x_all_included_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a Submission File to submit to Kaggle competition ##\n",
    "Submission.to_csv(\"XGBoost_test_x_all_included_pred.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the final XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(xgbFinal, open(\"XGBoost_test_x_all_included_pred_model.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the final XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBoost_test_x_all_included_pred_model = pickle.load(open(\"XGBoost_test_x_all_included_pred_model.pickle.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-forecast the prediction to verify the model\n",
    "XGBoost_pred = XGBoost_test_x_all_included_pred_model.predict(xgb.DMatrix(test_x_all_included))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Model, train_x_all_included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To have reproducible result with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 0\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "# 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(seed_value)\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "from keras import backend\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(units=256,activation = \"relu\", input_dim=299))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=128,activation = \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=64,activation = \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=32,activation = \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(9, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(lr=0.1, beta_1=0.9, beta_2=0.999, amsgrad=False, decay = 0.001)\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=100,baseline=None)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy') #loss = loss function\n",
    "print(backend.eval(model.optimizer.lr)) # print model learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x_all_included,train_x_all_included_class, validation_split = 0.05,\n",
    "          batch_size=(int(train_x_all_included.shape[0]*0.2)),\n",
    "          epochs=10000,verbose=1, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_per_epoch = pd.DataFrame(model.history.history)\n",
    "loss_per_epoch.iplot(y=[\"loss\",\"val_loss\"], title = \"loss_per_epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test_x Prediction for Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Neural_Network_test_x_all_included_pred = pd.DataFrame(model.predict(test_x_all_included))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission = pd.read_csv(\"sampleSubmission.csv\")\n",
    "Submission[['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6',\n",
    "       'Class_7', 'Class_8', 'Class_9']] = Neural_Network_test_x_all_included_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a Submission File to submit to Kaggle competition ##\n",
    "Submission.to_csv(\"Neural_Network_test_x_all_included_pred.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving NN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Neural_Network_test_x_all_included_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "Load_model = load_model('Neural_Network_test_x_all_included_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Load_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Neural_Network_test_x_all_included_pred = pd.DataFrame(Load_model.predict(test_x_all_included))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission = pd.read_csv(\"sampleSubmission.csv\")\n",
    "Submission[['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6',\n",
    "       'Class_7', 'Class_8', 'Class_9']] = Neural_Network_test_x_all_included_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a Submission File to submit to Kaggle competition ##\n",
    "Submission.to_csv(\"Neural_Network_test_x_all_included_pred.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Prediction, Weighted Average for XGBoost and Neural Network Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_pred = pd.read_csv(\"Neural_Network_test_x_selected_pred.csv\")\n",
    "XGBoost_pred = pd.read_csv(\"XGBoost_test_x_selected_pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weighted_Average_pred = (0.5*NN_pred) + (0.5*XGBoost_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Prediction, Weighted Average for XGBoost and Neural Network Prediction\n",
    "\n",
    "NN_pred = pd.read_csv(\"Neural_Network_test_x_selected_pred.csv\")\n",
    "XGBoost_pred = pd.read_csv(\"XGBoost_test_x_selected_pred.csv\")\n",
    "\n",
    "Weighted_Average_pred = (0.5*NN_pred) + (0.5*XGBoost_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
